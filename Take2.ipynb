{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/miniconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import requests, json, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_df = pd.concat([sci_clean, clean_fut_df])\n",
    "##RIght here if starting anew:\n",
    "sci_df = pd.read_csv('./data_csvs/clean_sci.csv')\n",
    "fut_df = pd.read_csv('./data_csvs/clean_fut.csv')\n",
    "master_df = pd.concat([sci_df, fut_df], ignore_index=True)\n",
    "#Drop the extraneous index column\n",
    "master_df.drop('Unnamed: 0', 1, inplace=True)\n",
    "\n",
    "\n",
    "#gonna map the subreddit to a 1 if 'askcience', 0 otherwise\n",
    "map_dict= {\n",
    "    \"askscience\": 1,\n",
    "    \"Futurology\": 0\n",
    "}\n",
    "master_df['subreddit'] = master_df['subreddit'].map(map_dict)\n",
    "\n",
    "#might as well remove selftext, num_comments, and ups because I don't want to use those right now\n",
    "dropfeats= ['ups', 'selftext', 'num_comments']\n",
    "master_df.drop(dropfeats, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**for feature engineering I will**:\n",
    "1. see if there's a question mark in the title (this is kind of cheating, may not use it ultimately)\n",
    "2. count the number of words\n",
    "3. count the number of words in title not in stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopWords = set(stopwords.words('english'))\n",
    "master_df['processed'] = master_df['title'].apply(lambda x: re.sub(r'[^\\w\\s]','', x.lower()))\n",
    "master_df['qmark']= master_df['title'].apply(lambda x: 1 if '?' in x else 0 )\n",
    "master_df['words_not_stopword'] = master_df['processed'].apply(lambda x: len([t for t in x.split(' ') if t not in stopWords]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Those are all the features I want now. Next step is to train_test_split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= master_df.drop(columns= ['subreddit', 'title'])\n",
    "y= master_df['subreddit']\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y)\n",
    "# X_train.columns = X_test.columns = ['data_'+col for col in X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= X_train.reset_index(drop=True)\n",
    "y_train= y_train.reset_index(drop=True)\n",
    "X_test= X_test.reset_index(drop=True)\n",
    "y_test= y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The main pre-processing I will be doing is EITHER CountVectorize or Tf-idf. words_not_stopwords is on approx the same scale, so I won't bother normalizing it. The main thing is to create a CV pipeline and a TFidf pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I would like to automate this process, but the best I can do atm is: \n",
    "#Create the different permutations of CV and TFIDF, save a different version of X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count Vecc options: Max_features, n_gram_range(), binary\n",
    "#TFIDF: \n",
    "cv= CountVectorizer(stop_words='english', ngram_range=(1,3)) \n",
    "tfidf= TfidfVectorizer(stop_words='english', ngram_range=(1,3))\n",
    "\n",
    "# Some Vectorizing notes:\n",
    "# When Stop words are left in, all the top features are stop words\n",
    "# When stop words are removed, test accuracy falls by about 4-5%\n",
    "# when ngram range starts >1, accuracy suffers. (1,3) is best\n",
    "\n",
    "trX_cv = cv.fit_transform(X_train['processed'])\n",
    "teX_cv= cv.transform(X_test['processed'])\n",
    "\n",
    "trX_tf = tfidf.fit_transform(X_train['processed'])\n",
    "teX_tf= tfidf.transform(X_test['processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.9038076152304609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('does', -7.9176303687593705),\n",
       " ('like', -8.52108110127995),\n",
       " ('water', -8.666734074146092),\n",
       " ('light', -8.808093004284842),\n",
       " ('sun', -8.828877641649086),\n",
       " ('space', -8.835347068947964),\n",
       " ('earth', -8.843391293265132),\n",
       " ('possible', -8.859137233099803),\n",
       " ('human', -8.990483738398865),\n",
       " ('body', -9.019797566547032)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf MultinomialNB()\n",
    "tf_mult= MultinomialNB()\n",
    "# tf_mult.fit(trX_tf.todense(), y_train) # Not needed to turn to dense\n",
    "tf_mult.fit(trX_tf, y_train)\n",
    "\n",
    "# print(tf_mult.score(trX_tf.todense(), y_train),tf_mult.score(teX_tf.todense(), y_test))\n",
    "print(tf_mult.score(trX_tf, y_train),tf_mult.score(teX_tf, y_test))\n",
    "\n",
    "tf_myd= dict(zip(tfidf.get_feature_names(), list(tf_mult.coef_)[0]))\n",
    "\n",
    "# to get a clue as to what's going on with NB, let's look at the coefs. The smallest magnitude words are the most\n",
    "# distinguishing\n",
    "\n",
    "sorted(tf_myd.items(), key= lambda x: abs(x[1]), reverse=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.8897795591182365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('does', -5.975155809066059),\n",
       " ('like', -6.7289276114424394),\n",
       " ('water', -6.9757876893739645),\n",
       " ('light', -7.224249048672465),\n",
       " ('just', -7.304291756346001),\n",
       " ('space', -7.332462633312698),\n",
       " ('earth', -7.361450170185949),\n",
       " ('time', -7.361450170185949),\n",
       " ('human', -7.422074792002384),\n",
       " ('possible', -7.453823490316965)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv MultinomialNB()cv_\n",
    "cv_mult= MultinomialNB()\n",
    "# cv_mult.fit(trX_cv.todense(), y_train)\n",
    "cv_mult.fit(trX_cv, y_train)\n",
    "\n",
    "# print(cv_mult.score(trX_cv.todense(), y_train),cv_mult.score(teX_cv.todense(), y_test))\n",
    "print(cv_mult.score(trX_cv, y_train),cv_mult.score(teX_cv, y_test))\n",
    "\n",
    "cv_myd= dict(zip(cv.get_feature_names(), list(cv_mult.coef_)[0]))\n",
    "\n",
    "# to get a clue as to what's going on with NB, let's look at the coefs. The smallest magnitude words are the most\n",
    "# distinguishing\n",
    "\n",
    "sorted(cv_myd.items(), key= lambda x: abs(x[1]), reverse=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I've settled on a somewhat acceptable CV/TFIDF. Now I'm going to insert them into their \n",
    "#respective DFs\n",
    "# vecdf_par =[\n",
    "#     (trX_cv, X_train)\n",
    "#     (trX_tf, X_train)\n",
    "#     (teX_cv, X_test)\n",
    "#     (teX_tf, X_test)    \n",
    "# ]\n",
    "cvdf_tr= pd.DataFrame(trX_cv.todense(), columns = cv.get_feature_names())\n",
    "cvdf_te= pd.DataFrame(teX_cv.todense(), columns = cv.get_feature_names())\n",
    "tfdf_tr= pd.DataFrame(trX_tf.todense(), columns = tfidf.get_feature_names())\n",
    "tfdf_te= pd.DataFrame(teX_tf.todense(), columns = tfidf.get_feature_names())\n",
    "cv_tr_df= pd.concat([X_train.drop(columns='processed'), cvdf_tr], axis=1)#, ignore_index=True)\n",
    "cv_te_df= pd.concat([X_test.drop(columns='processed'), cvdf_te], axis=1)#, ignore_index=True)\n",
    "tf_tr_df= pd.concat([X_train.drop(columns='processed'), tfdf_tr], axis=1)#, ignore_index=True)\n",
    "tf_te_df= pd.concat([X_test.drop(columns='processed'), tfdf_te], axis=1)#, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To Recap: Right now I have both TFIDF and Count Vectorized Corpuses. Now I will run them through various classifiers to see if I can get better**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#courtesy of http://www.davidsbatista.net/blog/2018/02/23/model_optimization/\n",
    "class EstimatorSelectionHelper:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv=3, n_jobs=3, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, refit=refit,\n",
    "                              return_train_score=True)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params,**d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            print(k)\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]        \n",
    "                scores.append(r.reshape(len(params),1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params,all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "models1 = {\n",
    "    'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    'SVC': SVC()\n",
    "}\n",
    "\n",
    "params1 = {\n",
    "    'ExtraTreesClassifier': { 'n_estimators': [16, 32] },\n",
    "    'RandomForestClassifier': { 'n_estimators': [16, 32] },\n",
    "    'AdaBoostClassifier':  { 'n_estimators': [16, 32] },\n",
    "    'GradientBoostingClassifier': { 'n_estimators': [16, 32], 'learning_rate': [0.8, 1.0] },\n",
    "    'SVC': [\n",
    "        {'kernel': ['linear'], 'C': [1, 10]},\n",
    "        {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.001, 0.0001]},\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Running GridSearchCV for RandomForestClassifier.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done   6 out of   6 | elapsed:    9.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done   6 out of   6 | elapsed:    8.5s finished\n",
      "[Parallel(n_jobs=7)]: Done   6 out of   6 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/omar/miniconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/omar/miniconda3/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/omar/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 405, in _handle_workers\n",
      "    pool._maintain_pool()\n",
      "  File \"/home/omar/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 246, in _maintain_pool\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/omar/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 239, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/home/omar/miniconda3/lib/python3.6/multiprocessing/process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/home/omar/miniconda3/lib/python3.6/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/home/omar/miniconda3/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/home/omar/miniconda3/lib/python3.6/multiprocessing/popen_fork.py\", line 66, in _launch\n",
      "    self.pid = os.fork()\n",
      "OSError: [Errno 12] Cannot allocate memory\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'terminate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/omar/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/omar/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/omar/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/omar/miniconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/omar/miniconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\", line 979, in fit\n    X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'], dtype=DTYPE)\n  File \"/home/omar/miniconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 573, in check_X_y\n    ensure_min_features, warn_on_dtype, estimator)\n  File \"/home/omar/miniconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 433, in check_array\n    array = np.array(array, dtype=dtype, order=order, copy=copy)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/omar/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/omar/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nMemoryError                                        Thu Sep  6 16:02:24 2018\nPID: 5442                    Python 3.6.5: /home/omar/miniconda3/bin/python\n...........................................................................\n/home/omar/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False),       qmark  words_not_stopword  00  00001  0000...  0  \n1496       0  \n\n[1497 rows x 56159 columns], 0       0\n1       1\n2       0\n3       1\n4       ...    0\nName: subreddit, Length: 1497, dtype: int64, {'score': make_scorer(f1_score)}, array([ 464,  466,  469,  471,  473,  474,  475,...       1490, 1491, 1492, 1493, 1494, 1495, 1496]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 516, 517,\n       520, 524, 526, 533, 534, 537]), 1, {'learning_rate': 0.8, 'n_estimators': 32}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/omar/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False),       qmark  words_not_stopword  00  00001  0000...  0  \n1496       0  \n\n[1497 rows x 56159 columns], 0       0\n1       1\n2       0\n3       1\n4       ...    0\nName: subreddit, Length: 1497, dtype: int64, {'score': make_scorer(f1_score)}, array([ 464,  466,  469,  471,  473,  474,  475,...       1490, 1491, 1492, 1493, 1494, 1495, 1496]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 516, 517,\n       520, 524, 526, 533, 534, 537]), 1, {'learning_rate': 0.8, 'n_estimators': 32})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/omar/miniconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), X=      qmark  words_not_stopword  00  00001  0000...  0  \n1496       0  \n\n[1497 rows x 56159 columns], y=0       0\n1       1\n2       0\n3       1\n4       ...    0\nName: subreddit, Length: 1497, dtype: int64, scorer={'score': make_scorer(f1_score)}, train=array([ 464,  466,  469,  471,  473,  474,  475,...       1490, 1491, 1492, 1493, 1494, 1495, 1496]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 516, 517,\n       520, 524, 526, 533, 534, 537]), verbose=1, parameters={'learning_rate': 0.8, 'n_estimators': 32}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseGradientBoosting.fit of Gradie...=1.0, verbose=0,\n              warm_start=False)>\n        X_train =       qmark  words_not_stopword  00  00001  0000...   0  \n1496       0  \n\n[997 rows x 56159 columns]\n        y_train = 464     0\n466     0\n469     0\n471     0\n473     ...6    0\nName: subreddit, Length: 997, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/omar/miniconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py in fit(self=GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), X=      qmark  words_not_stopword  00  00001  0000...   0  \n1496       0  \n\n[997 rows x 56159 columns], y=464     0\n466     0\n469     0\n471     0\n473     ...6    0\nName: subreddit, Length: 997, dtype: int64, sample_weight=None, monitor=None)\n    974         # if not warmstart - clear the estimator state\n    975         if not self.warm_start:\n    976             self._clear_state()\n    977 \n    978         # Check input\n--> 979         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'], dtype=DTYPE)\n        X =       qmark  words_not_stopword  00  00001  0000...   0  \n1496       0  \n\n[997 rows x 56159 columns]\n        y = 464     0\n466     0\n469     0\n471     0\n473     ...6    0\nName: subreddit, Length: 997, dtype: int64\n    980         n_samples, self.n_features_ = X.shape\n    981         if sample_weight is None:\n    982             sample_weight = np.ones(n_samples, dtype=np.float32)\n    983         else:\n\n...........................................................................\n/home/omar/miniconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in check_X_y(X=      qmark  words_not_stopword  00  00001  0000...   0  \n1496       0  \n\n[997 rows x 56159 columns], y=464     0\n466     0\n469     0\n471     0\n473     ...6    0\nName: subreddit, Length: 997, dtype: int64, accept_sparse=['csr', 'csc', 'coo'], dtype=<class 'numpy.float32'>, order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, multi_output=False, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, warn_on_dtype=False, estimator=None)\n    568     y_converted : object\n    569         The converted and validated y.\n    570     \"\"\"\n    571     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n    572                     ensure_2d, allow_nd, ensure_min_samples,\n--> 573                     ensure_min_features, warn_on_dtype, estimator)\n        ensure_min_features = 1\n        warn_on_dtype = False\n        estimator = None\n    574     if multi_output:\n    575         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n    576                         dtype=None)\n    577     else:\n\n...........................................................................\n/home/omar/miniconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array=      qmark  words_not_stopword  00  00001  0000...   0  \n1496       0  \n\n[997 rows x 56159 columns], accept_sparse=['csr', 'csc', 'coo'], dtype=<class 'numpy.float32'>, order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    428 \n    429     if sp.issparse(array):\n    430         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n    431                                       force_all_finite)\n    432     else:\n--> 433         array = np.array(array, dtype=dtype, order=order, copy=copy)\n        array =       qmark  words_not_stopword  00  00001  0000...   0  \n1496       0  \n\n[997 rows x 56159 columns]\n        dtype = <class 'numpy.float32'>\n        order = None\n        copy = False\n    434 \n    435         if ensure_2d:\n    436             if array.ndim == 1:\n    437                 raise ValueError(\n\nMemoryError: \n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nMemoryError                                        Thu Sep  6 16:02:24 2018\nPID: 5442                    Python 3.6.5: /home/omar/miniconda3/bin/python\n...........................................................................\n/home/omar/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False),       qmark  words_not_stopword  00  00001  0000...  0  \n1496       0  \n\n[1497 rows x 56159 columns], 0       0\n1       1\n2       0\n3       1\n4       ...    0\nName: subreddit, Length: 1497, dtype: int64, {'score': make_scorer(f1_score)}, array([ 464,  466,  469,  471,  473,  474,  475,...       1490, 1491, 1492, 1493, 1494, 1495, 1496]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 516, 517,\n       520, 524, 526, 533, 534, 537]), 1, {'learning_rate': 0.8, 'n_estimators': 32}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/omar/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False),       qmark  words_not_stopword  00  00001  0000...  0  \n1496       0  \n\n[1497 rows x 56159 columns], 0       0\n1       1\n2       0\n3       1\n4       ...    0\nName: subreddit, Length: 1497, dtype: int64, {'score': make_scorer(f1_score)}, array([ 464,  466,  469,  471,  473,  474,  475,...       1490, 1491, 1492, 1493, 1494, 1495, 1496]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 516, 517,\n       520, 524, 526, 533, 534, 537]), 1, {'learning_rate': 0.8, 'n_estimators': 32})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/omar/miniconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), X=      qmark  words_not_stopword  00  00001  0000...  0  \n1496       0  \n\n[1497 rows x 56159 columns], y=0       0\n1       1\n2       0\n3       1\n4       ...    0\nName: subreddit, Length: 1497, dtype: int64, scorer={'score': make_scorer(f1_score)}, train=array([ 464,  466,  469,  471,  473,  474,  475,...       1490, 1491, 1492, 1493, 1494, 1495, 1496]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 516, 517,\n       520, 524, 526, 533, 534, 537]), verbose=1, parameters={'learning_rate': 0.8, 'n_estimators': 32}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseGradientBoosting.fit of Gradie...=1.0, verbose=0,\n              warm_start=False)>\n        X_train =       qmark  words_not_stopword  00  00001  0000...   0  \n1496       0  \n\n[997 rows x 56159 columns]\n        y_train = 464     0\n466     0\n469     0\n471     0\n473     ...6    0\nName: subreddit, Length: 997, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/omar/miniconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py in fit(self=GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), X=      qmark  words_not_stopword  00  00001  0000...   0  \n1496       0  \n\n[997 rows x 56159 columns], y=464     0\n466     0\n469     0\n471     0\n473     ...6    0\nName: subreddit, Length: 997, dtype: int64, sample_weight=None, monitor=None)\n    974         # if not warmstart - clear the estimator state\n    975         if not self.warm_start:\n    976             self._clear_state()\n    977 \n    978         # Check input\n--> 979         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'], dtype=DTYPE)\n        X =       qmark  words_not_stopword  00  00001  0000...   0  \n1496       0  \n\n[997 rows x 56159 columns]\n        y = 464     0\n466     0\n469     0\n471     0\n473     ...6    0\nName: subreddit, Length: 997, dtype: int64\n    980         n_samples, self.n_features_ = X.shape\n    981         if sample_weight is None:\n    982             sample_weight = np.ones(n_samples, dtype=np.float32)\n    983         else:\n\n...........................................................................\n/home/omar/miniconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in check_X_y(X=      qmark  words_not_stopword  00  00001  0000...   0  \n1496       0  \n\n[997 rows x 56159 columns], y=464     0\n466     0\n469     0\n471     0\n473     ...6    0\nName: subreddit, Length: 997, dtype: int64, accept_sparse=['csr', 'csc', 'coo'], dtype=<class 'numpy.float32'>, order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, multi_output=False, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, warn_on_dtype=False, estimator=None)\n    568     y_converted : object\n    569         The converted and validated y.\n    570     \"\"\"\n    571     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n    572                     ensure_2d, allow_nd, ensure_min_samples,\n--> 573                     ensure_min_features, warn_on_dtype, estimator)\n        ensure_min_features = 1\n        warn_on_dtype = False\n        estimator = None\n    574     if multi_output:\n    575         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n    576                         dtype=None)\n    577     else:\n\n...........................................................................\n/home/omar/miniconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array=      qmark  words_not_stopword  00  00001  0000...   0  \n1496       0  \n\n[997 rows x 56159 columns], accept_sparse=['csr', 'csc', 'coo'], dtype=<class 'numpy.float32'>, order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    428 \n    429     if sp.issparse(array):\n    430         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n    431                                       force_all_finite)\n    432     else:\n--> 433         array = np.array(array, dtype=dtype, order=order, copy=copy)\n        array =       qmark  words_not_stopword  00  00001  0000...   0  \n1496       0  \n\n[997 rows x 56159 columns]\n        dtype = <class 'numpy.float32'>\n        order = None\n        copy = False\n    434 \n    435         if ensure_2d:\n    436             if array.ndim == 1:\n    437                 raise ValueError(\n\nMemoryError: \n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-67f3b5ed62ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhelper1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEstimatorSelectionHelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhelper1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_tr_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-138-dbccd11464fd>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cv, n_jobs, verbose, scoring, refit)\u001b[0m\n\u001b[1;32m     19\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                               return_train_score=True)\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_searches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    638\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    639\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 640\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m                     \u001b[0;31m# scheduling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mabort_everything\u001b[0;34m(self, ensure_ready)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;34m\"\"\"Shutdown the pool and restart a new one with the same parameters\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             self.configure(n_jobs=self.parallel.n_jobs, parallel=self.parallel,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;34m\"\"\"Shutdown the process or thread pool\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultiprocessingBackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOBLIB_SPAWNED_PROCESS\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOBLIB_SPAWNED_PROCESS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# terminate does a join()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m                 \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMemmapingPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_terminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/multiprocessing/util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wr, _finalizer_registry, sub_debug, getpid)\u001b[0m\n\u001b[1;32m    184\u001b[0m                 sub_debug('finalizer calling %s with args %s and kwargs %s',\n\u001b[1;32m    185\u001b[0m                           self._callback, self._args, self._kwargs)\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weakref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_terminate_pool\u001b[0;34m(cls, taskqueue, inqueue, outqueue, pool, worker_handler, task_handler, result_handler, cache)\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitcode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'joining task handler'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mTerminate\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0msends\u001b[0m \u001b[0mSIGTERM\u001b[0m \u001b[0msignal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0muses\u001b[0m \u001b[0mTerminateProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         '''\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'terminate'"
     ]
    }
   ],
   "source": [
    "# Do not run this because my computer nearly crashed and ran out of memory\n",
    "helper1 = EstimatorSelectionHelper(models1, params1)\n",
    "helper1.fit(cv_tr_df, y_train, scoring='f1', n_jobs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n",
      "RandomForestClassifier\n",
      "AdaBoostClassifier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.980397</td>\n",
       "      <td>0.981744</td>\n",
       "      <td>0.00185262</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.977597</td>\n",
       "      <td>0.97904</td>\n",
       "      <td>0.981744</td>\n",
       "      <td>0.00191399</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.977867</td>\n",
       "      <td>0.9791</td>\n",
       "      <td>0.979757</td>\n",
       "      <td>0.000872151</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.971545</td>\n",
       "      <td>0.974947</td>\n",
       "      <td>0.977688</td>\n",
       "      <td>0.0025512</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.953908</td>\n",
       "      <td>0.960749</td>\n",
       "      <td>0.965377</td>\n",
       "      <td>0.00493693</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.930612</td>\n",
       "      <td>0.941297</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.00857746</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                estimator min_score mean_score max_score    std_score  \\\n",
       "1    ExtraTreesClassifier  0.977778   0.980397  0.981744   0.00185262   \n",
       "5      AdaBoostClassifier  0.977597    0.97904  0.981744   0.00191399   \n",
       "4      AdaBoostClassifier  0.977867     0.9791  0.979757  0.000872151   \n",
       "0    ExtraTreesClassifier  0.971545   0.974947  0.977688    0.0025512   \n",
       "3  RandomForestClassifier  0.953908   0.960749  0.965377   0.00493693   \n",
       "2  RandomForestClassifier  0.930612   0.941297  0.951613   0.00857746   \n",
       "\n",
       "  n_estimators  \n",
       "1           32  \n",
       "5           32  \n",
       "4           16  \n",
       "0           16  \n",
       "3           32  \n",
       "2           16  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what I have left over before the crash\n",
    "helper1.score_summary(sort_by='max_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=32)\n",
    "et.fit(cv_tr_df, y_train)\n",
    "\n",
    "et.score(cv_tr_df, y_train) #Returns 1\n",
    "\n",
    "et.score(cv_te_df, y_test) # Returns .98, not bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7feff8b982e8>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importance = pd.DataFrame(et.feature_importances_, cv_tr_df.columns, columns = ['importance'])\n",
    "\n",
    "feat_importance.sort_values('importance', ascending=False).head(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#same concept but with tf_tr_df\n",
    "et2 = ExtraTreesClassifier(n_estimators=32)\n",
    "et2.fit(tf_tr_df, y_train)\n",
    "\n",
    "et2.score(tf_tr_df, y_train) #Returns 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9639278557114228"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et2.score(tf_te_df, y_test) # Returns .96, not as good as count vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7feff89d2198>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importance2 = pd.DataFrame(et2.feature_importances_, tf_tr_df.columns, columns = ['importance'])\n",
    "\n",
    "feat_importance2.sort_values('importance', ascending=False).head(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As expected, the qmark feature is highly important, but it is kind of cheating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_params= [\n",
    "        {'kernel': ['linear'], 'C': [1, 10]},\n",
    "        {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.001, 0.0001]},\n",
    "    ]\n",
    "svc_grid = GridSearchCV(SVC(), svc_params, n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=5,\n",
       "       param_grid=[{'kernel': ['linear'], 'C': [1, 10]}, {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.001, 0.0001]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_grid.fit(cv_tr_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsvc= svc_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_grid.score(cv_tr_df, y_train) #1.0\n",
    "\n",
    "svc_grid.score(cv_te_df, y_test) #0.9799599198396793"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVC is way too computationally expensive. Let's try gradient boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=5,\n",
       "       param_grid={'n_estimators': [16, 32], 'learning_rate': [0.8, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_params= { \n",
    "    'n_estimators': [16, 32],\n",
    "    'learning_rate': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "gb_grid = GridSearchCV(GradientBoostingClassifier(), gb_params, cv= 5, n_jobs=5)\n",
    "gb_grid.fit(cv_tr_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_grid.score(cv_tr_df, y_train) #1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9819639278557114"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_grid.score(cv_te_df, y_test) #0.9819639278557114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-25:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/omar/miniconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/omar/miniconda3/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/omar/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 405, in _handle_workers\n",
      "    pool._maintain_pool()\n",
      "  File \"/home/omar/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 246, in _maintain_pool\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/omar/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 239, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/home/omar/miniconda3/lib/python3.6/multiprocessing/process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/home/omar/miniconda3/lib/python3.6/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/home/omar/miniconda3/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/home/omar/miniconda3/lib/python3.6/multiprocessing/popen_fork.py\", line 66, in _launch\n",
      "    self.pid = os.fork()\n",
      "OSError: [Errno 12] Cannot allocate memory\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'terminate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-eb95a4dda8d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgb_grid2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgb_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgb_grid2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_tr_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    638\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    639\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 640\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m                     \u001b[0;31m# scheduling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mabort_everything\u001b[0;34m(self, ensure_ready)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;34m\"\"\"Shutdown the pool and restart a new one with the same parameters\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             self.configure(n_jobs=self.parallel.n_jobs, parallel=self.parallel,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;34m\"\"\"Shutdown the process or thread pool\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultiprocessingBackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOBLIB_SPAWNED_PROCESS\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOBLIB_SPAWNED_PROCESS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# terminate does a join()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m                 \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMemmapingPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_terminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/multiprocessing/util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wr, _finalizer_registry, sub_debug, getpid)\u001b[0m\n\u001b[1;32m    184\u001b[0m                 sub_debug('finalizer calling %s with args %s and kwargs %s',\n\u001b[1;32m    185\u001b[0m                           self._callback, self._args, self._kwargs)\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weakref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_terminate_pool\u001b[0;34m(cls, taskqueue, inqueue, outqueue, pool, worker_handler, task_handler, result_handler, cache)\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitcode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'joining task handler'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mTerminate\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0msends\u001b[0m \u001b[0mSIGTERM\u001b[0m \u001b[0msignal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0muses\u001b[0m \u001b[0mTerminateProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         '''\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'terminate'"
     ]
    }
   ],
   "source": [
    "#Now test GradBoost with TFIDF\n",
    "\n",
    "gb_grid2 = GridSearchCV(GradientBoostingClassifier(), gb_params, cv= 5, n_jobs=6)\n",
    "gb_grid2.fit(tf_tr_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_grid2.score(tf_tr_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_grid2.score(tf_te_df, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next step is to test GradBoost with TFIDF, then decided if tfidf or count vec are more effective.\n",
    "# Then remove the qmark column, and try it that way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since I don't want to use meta info (like q mark), I'll just run off the sparse transformed matrices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count Vecc options: Max_features, n_gram_range(), binary\n",
    "#TFIDF: \n",
    "cv= CountVectorizer(stop_words=None, ngram_range=(1,3)) \n",
    "tfidf= TfidfVectorizer(stop_words=None, ngram_range=(1,3))\n",
    "\n",
    "# Some Vectorizing notes:\n",
    "# When Stop words are left in, all the top features are stop words\n",
    "# When stop words are removed, test accuracy falls by about 4-5%\n",
    "# when ngram range starts >1, accuracy suffers. (1,3) is best\n",
    "\n",
    "trX_cv = cv.fit_transform(X_train['processed'])\n",
    "teX_cv= cv.transform(X_test['processed'])\n",
    "\n",
    "trX_tf = tfidf.fit_transform(X_train['processed'])\n",
    "teX_tf= tfidf.transform(X_test['processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9602649 , 0.96      , 0.96666667, 0.95333333, 0.96      ,\n",
       "       0.92      , 0.95973154, 0.91946309, 0.97315436, 0.95302013])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2_params= {\n",
    "    {'kernel': ['linear'], 'C': [1, 10]},\n",
    "        {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.001, 0.0001]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=7,\n",
       "       param_grid={'n_estimators': [50, 80], 'learning_rate': [0.25, 0.15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_params= { \n",
    "    'n_estimators': [50, 80],\n",
    "    'learning_rate': [0.25, .15]\n",
    "}\n",
    "\n",
    "cv_gb = GridSearchCV(GradientBoostingClassifier(), gb_params, cv= 5, n_jobs=7, scoring='f1')\n",
    "cv_gb.fit(trX_cv, y_train)\n",
    "\n",
    "tf_gb = GridSearchCV(GradientBoostingClassifier(), gb_params, cv= 5, n_jobs=7, scoring='f1')\n",
    "tf_gb.fit(trX_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9927963326784545, 0.9241071428571428)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_gb.score(trX_cv, y_train),cv_gb.score(teX_cv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9947575360419397, 0.9166666666666666)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_gb.score(trX_tf, y_train),tf_gb.score(teX_tf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.25, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=80,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_gb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.25, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=80,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_gb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the above process into a function\n",
    "def double_class(classifier, params, dense=False):\n",
    "    cv_grid = tf_grid = GridSearchCV(classifier, params, cv= 5, n_jobs=7)#, scoring= 'f1')\n",
    "    cv_grid.fit(trX_cv, y_train)\n",
    "    tf_grid.fit(trX_tf, y_train)\n",
    "    print('CV Stats:')\n",
    "    print(cv_grid.score(trX_cv, y_train),cv_grid.score(teX_cv, y_test))\n",
    "    print(cv_grid.best_estimator_)\n",
    "#     print(cv_grid.get_params())\n",
    "    print('\\nTF Stats:')\n",
    "    print(tf_grid.score(trX_tf, y_train),tf_grid.score(teX_tf, y_test))\n",
    "    print(tf_grid.best_estimator_) \n",
    "#     print(tf_grid.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Stats:\n",
      "0.9986639946559787 0.9639278557114228\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "\n",
      "TF Stats:\n",
      "1.0 0.9639278557114228\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    }
   ],
   "source": [
    "nbayes= MultinomialNB()\n",
    "nbayes_params={\n",
    "    \n",
    "}\n",
    "double_class(nbayes, nbayes_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Stats:\n",
      "1.0 0.9498997995991983\n",
      "GaussianNB(priors=None)\n",
      "\n",
      "TF Stats:\n",
      "1.0 0.9278557114228457\n",
      "GaussianNB(priors=None)\n"
     ]
    }
   ],
   "source": [
    "gbayes = GaussianNB() #It doesn't take a sparse matrix, so double_class won't work. \n",
    "\n",
    "tf_gnb = cv_gnb = GridSearchCV(gbayes, {}, n_jobs=7, cv=5)\n",
    "tf_gnb.fit(trX_tf.toarray(), y_train)\n",
    "cv_gnb.fit(trX_cv.toarray(), y_train)\n",
    "print('CV Stats:')\n",
    "print(cv_gnb.score(trX_cv.toarray(), y_train),cv_gnb.score(teX_cv.toarray(), y_test))\n",
    "print(cv_gnb.best_estimator_)\n",
    "#     print(cv_grid.get_params())\n",
    "print('\\nTF Stats:')\n",
    "print(tf_gnb.score(trX_tf.toarray(), y_train),tf_gnb.score(teX_tf.toarray(), y_test))\n",
    "print(tf_gnb.best_estimator_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Stats: \n",
      "\n",
      "0.8390113560454242 0.8176352705410822\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=14, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "TF Stats: \n",
      "\n",
      "0.9245156980627922 0.8276553106212425\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=14, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "ranfor= RandomForestClassifier()\n",
    "ranfor_params = {\n",
    "    'n_estimators': [6, 10, 15],\n",
    "    'max_depth' : [5, 9, 14]\n",
    "}\n",
    "double_class(ranfor, ranfor_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Stats: \n",
      "\n",
      "0.9612558450233801 0.9198396793587175\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "TF Stats: \n",
      "\n",
      "0.978623914495658 0.9218436873747495\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "extree= ExtraTreesClassifier(n_estimators=50, max_depth=20)\n",
    "extree_params = {\n",
    "#     'min_samples_leaf': [.005, .01, .02], # Even with full range of parameters, the ExtraTrees is overfitting,\n",
    "#     'min_samples_split': [.01, .1, .15]   # and under performing\n",
    "}\n",
    "double_class(extree, extree_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Stats: \n",
      "\n",
      "0.822311289245157 0.843687374749499\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=25,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=0.007, min_samples_split=0.1,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "TF Stats: \n",
      "\n",
      "0.8984635938543755 0.8677354709418837\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=25,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=0.007, min_samples_split=0.1,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc_params = {\n",
    "    'max_depth': [25, 18, 20],\n",
    "#     'max_features': ['sqrt', 'log2', .6]\n",
    "    'min_samples_leaf': [.007, .008],#, .05],\n",
    "    'min_samples_split': [.1, .07, .05]\n",
    "}\n",
    "double_class(dtc, dtc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Stats:\n",
      "0.9986639946559787 0.9579158316633266\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      "TF Stats:\n",
      "1.0 0.9779559118236473\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc_params={\n",
    "    'C': [.3, .8, 1],\n",
    "    'kernel': ['rbf', 'linear', 'poly']\n",
    "}\n",
    "\n",
    "double_class(svc, svc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Stats:\n",
      "0.9759519038076152 0.9458917835671342\n",
      "LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "TF Stats:\n",
      "0.9986639946559787 0.969939879759519\n",
      "LogisticRegression(C=0.9, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "logreg= LogisticRegression()\n",
    "logreg_params = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [.05, .1, .2, .5, .9, 1]\n",
    "}\n",
    "double_class(logreg, logreg_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVC with TFIDF seems to be performing the best, so I will fit a pipeline with both of those and Grid Search more deeply**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Also going to include various Tokenizers\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
    "\n",
    "class SnowballTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.sbs = SnowballStemmer('english')\n",
    "    def __call__(self, doc):\n",
    "        return [self.sbs.stem(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_svc= Pipeline(steps=[\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,4), tokenizer=SnowballTokenizer())),\n",
    "    ('svc', SVC(kernel='linear' ))\n",
    "])\n",
    "\n",
    "pipe_params={\n",
    "#     'tfidf__tokenizer':[None, LemmaTokenizer(), SnowballTokenizer() ],#, SnowballStemmer],# SnowballTokenizer(), LemmaTokenizer()], \n",
    "    'tfidf__max_features': [9000, 9500, 9750],#9000, 10000],\n",
    "#     'tfidf__stop_words': [None, 'english'],\n",
    "#     'tfidf__ngram_range':[(1,3), (1,4)],\n",
    "    'svc__C':[.7, .75,  .8, .85],\n",
    "#     'svc__'\n",
    "#     'svc__'\n",
    "    \n",
    "}\n",
    "\n",
    "tfsvc_grid= GridSearchCV(tf_svc, pipe_params, cv= 5, n_jobs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9959919839679359 0.9799599198396793\n"
     ]
    }
   ],
   "source": [
    "#take2\n",
    "tfsvc_grid.fit(X_train['processed'], y_train)\n",
    "\n",
    "print(tfsvc_grid.score(X_train['processed'], y_train),tfsvc_grid.score(X_test['processed'], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 0.8, 'tfidf__max_features': 9500}\n"
     ]
    }
   ],
   "source": [
    "# Cinco tuning\n",
    "print(tfsvc_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 0.8, 'tfidf__max_features': 9500}\n"
     ]
    }
   ],
   "source": [
    "# Quatro tuning\n",
    "print(tfsvc_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 0.8, 'tfidf__max_features': 9500}\n"
     ]
    }
   ],
   "source": [
    "# Third tuning\n",
    "print(tfsvc_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 0.7, 'tfidf__max_features': 9000, 'tfidf__ngram_range': (1, 4), 'tfidf__tokenizer': <__main__.SnowballTokenizer object at 0x7fd916ce72b0>}\n"
     ]
    }
   ],
   "source": [
    "# Second tuning\n",
    "print(tfsvc_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 0.8, 'tfidf__max_features': 9000, 'tfidf__ngram_range': (1, 4), 'tfidf__tokenizer': <__main__.SnowballTokenizer object at 0x7fd915e24780>}\n"
     ]
    }
   ],
   "source": [
    "# First one\n",
    "print(tfsvc_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'if': 2758,\n",
       " 'the': 7340,\n",
       " 'graviti': 2421,\n",
       " 'of': 3930,\n",
       " 'moon': 3701,\n",
       " 'is': 3038,\n",
       " 'enough': 1940,\n",
       " 'to': 7806,\n",
       " 'creat': 1482,\n",
       " 'tidal': 7773,\n",
       " 'wave': 8264,\n",
       " 'whi': 8403,\n",
       " 'doesnt': 1738,\n",
       " 'it': 3147,\n",
       " 'lift': 3406,\n",
       " 'up': 8144,\n",
       " 'thing': 7728,\n",
       " 'like': 3423,\n",
       " 'tree': 8061,\n",
       " 'leav': 3368,\n",
       " 'or': 4141,\n",
       " 'small': 6868,\n",
       " 'anim': 585,\n",
       " 'if the': 2785,\n",
       " 'the graviti': 7442,\n",
       " 'of the': 4014,\n",
       " 'the moon': 7487,\n",
       " 'moon is': 3706,\n",
       " 'enough to': 1945,\n",
       " 'to creat': 7847,\n",
       " 'whi doesnt': 8425,\n",
       " 'thing like': 7729,\n",
       " 'of the moon': 4019,\n",
       " 'common': 1352,\n",
       " 'in': 2818,\n",
       " 'young': 8979,\n",
       " 'adult': 358,\n",
       " 'when': 8375,\n",
       " 'i': 2730,\n",
       " 'assum': 732,\n",
       " 'this': 7739,\n",
       " 'would': 8908,\n",
       " 'have': 2512,\n",
       " 'been': 890,\n",
       " 'a': 134,\n",
       " 'serious': 6778,\n",
       " 'disadvantag': 1647,\n",
       " 'we': 8275,\n",
       " 'were': 8326,\n",
       " 'whi is': 8430,\n",
       " 'common in': 1354,\n",
       " 'when i': 8380,\n",
       " 'would have': 8914,\n",
       " 'have been': 2516,\n",
       " 'been a': 891,\n",
       " 'a serious': 254,\n",
       " 'when we': 8390,\n",
       " 'we were': 8307,\n",
       " 'what': 8340,\n",
       " 'make': 3521,\n",
       " 'food': 2181,\n",
       " 'fill': 2114,\n",
       " 'just': 3261,\n",
       " 'calori': 1099,\n",
       " 'what make': 8362,\n",
       " 'make a': 3522,\n",
       " 'is it': 3074,\n",
       " 'it just': 3193,\n",
       " 'is it just': 3077,\n",
       " 'elon': 1884,\n",
       " 'musk': 3770,\n",
       " 'say': 6679,\n",
       " 'bore': 991,\n",
       " 'compani': 1359,\n",
       " 'will': 8469,\n",
       " 'offer': 4052,\n",
       " 'free': 2259,\n",
       " 'ride': 6603,\n",
       " 'public': 6407,\n",
       " 'year': 8943,\n",
       " 'elon musk': 1885,\n",
       " 'musk say': 3774,\n",
       " 'bore compani': 992,\n",
       " 'offer free': 4054,\n",
       " 'to the': 7983,\n",
       " 'this year': 7750,\n",
       " 'elon musk say': 1889,\n",
       " 'that': 7289,\n",
       " 'you': 8959,\n",
       " 'add': 347,\n",
       " 'ani': 575,\n",
       " 'sequenc': 6771,\n",
       " 'number': 3908,\n",
       " '1': 2,\n",
       " '2': 42,\n",
       " '3': 76,\n",
       " '4': 89,\n",
       " '5': 101,\n",
       " '6': 110,\n",
       " '7': 119,\n",
       " '8': 124,\n",
       " 'alway': 434,\n",
       " 'squar': 7023,\n",
       " 'largest': 3340,\n",
       " 'it that': 3227,\n",
       " 'that if': 7311,\n",
       " 'if you': 2797,\n",
       " 'of number': 3993,\n",
       " '1 the': 7,\n",
       " 'is alway': 3047,\n",
       " 'the largest': 7473,\n",
       " 'whi is it': 8431,\n",
       " 'is it that': 3085,\n",
       " 'whi is it that': 8433,\n",
       " 'world': 8895,\n",
       " 'first': 2128,\n",
       " 'passeng': 4414,\n",
       " 'train': 8044,\n",
       " 'come': 1335,\n",
       " 'germani': 2342,\n",
       " 'the world': 7644,\n",
       " 'world first': 8898,\n",
       " 'passeng train': 4415,\n",
       " 'is come': 3053,\n",
       " 'come to': 1341,\n",
       " 'the world first': 7645,\n",
       " 'is come to': 3054,\n",
       " 'how': 2632,\n",
       " 'do': 1676,\n",
       " 'tie': 7774,\n",
       " 'themselv': 7664,\n",
       " 'how do': 2651,\n",
       " 'do thing': 1701,\n",
       " 'themselv up': 7665,\n",
       " 'doe': 1711,\n",
       " 'electr': 1859,\n",
       " 'at': 737,\n",
       " 'pitch': 4724,\n",
       " 'whi doe': 8421,\n",
       " 'at a': 742,\n",
       " 'odour': 3929,\n",
       " 'spray': 7019,\n",
       " 'elimin': 1879,\n",
       " 'air': 393,\n",
       " 'in the': 2910,\n",
       " 'the air': 7347,\n",
       " 'in the air': 2911,\n",
       " 'can': 1104,\n",
       " 'remov': 6532,\n",
       " 'trillion': 8070,\n",
       " 'ton': 8020,\n",
       " 'carbon': 1158,\n",
       " 'from': 2265,\n",
       " 'atmospher': 756,\n",
       " 'ocean': 3924,\n",
       " 'explain': 2026,\n",
       " 'restor': 6584,\n",
       " 'lower': 3500,\n",
       " 'greenhous': 2431,\n",
       " 'gase': 2324,\n",
       " 'and': 484,\n",
       " 'bring': 1021,\n",
       " 'back': 788,\n",
       " 'fish': 2142,\n",
       " 'level': 3396,\n",
       " 'not': 3874,\n",
       " 'seen': 6748,\n",
       " 'for': 2187,\n",
       " 'generat': 2333,\n",
       " 'can we': 1128,\n",
       " 'ton of': 8021,\n",
       " 'of carbon': 3953,\n",
       " 'carbon from': 1161,\n",
       " 'from the': 2281,\n",
       " 'the atmospher': 7350,\n",
       " 'explain how': 2027,\n",
       " 'greenhous gase': 2434,\n",
       " 'gase and': 2325,\n",
       " 'bring back': 1022,\n",
       " 'ton of carbon': 8022,\n",
       " 'from the atmospher': 2283,\n",
       " 'greenhous gase and': 2435,\n",
       " 'specif': 6992,\n",
       " 'design': 1600,\n",
       " 'so': 6882,\n",
       " 'modern': 3689,\n",
       " 'jet': 3249,\n",
       " 'is this': 3130,\n",
       " 'antimatt': 601,\n",
       " 'store': 7076,\n",
       " 'how is': 2670,\n",
       " 'chatbot': 1225,\n",
       " 'lawyer': 3354,\n",
       " '160000': 37,\n",
       " 'park': 4402,\n",
       " 'ticket': 7772,\n",
       " 'london': 3467,\n",
       " 'new': 3831,\n",
       " 'york': 8958,\n",
       " 'in london': 2876,\n",
       " 'new york': 3845,\n",
       " 'work': 8885,\n",
       " 'with': 8606,\n",
       " 'trump': 8077,\n",
       " 'on': 4067,\n",
       " 'climat': 1283,\n",
       " 'chang': 1212,\n",
       " 'offer to': 4055,\n",
       " 'to work': 8011,\n",
       " 'work with': 8890,\n",
       " 'on climat': 4079,\n",
       " 'climat chang': 1286,\n",
       " 'to work with': 8012,\n",
       " 'on climat chang': 4080,\n",
       " 'wind': 8495,\n",
       " 'power': 5655,\n",
       " 'reach': 6465,\n",
       " 'job': 3250,\n",
       " 'mileston': 3647,\n",
       " 'now': 3889,\n",
       " 'employ': 1907,\n",
       " 'more': 3708,\n",
       " 'worker': 8891,\n",
       " 'than': 7276,\n",
       " 'nuclear': 3896,\n",
       " 'natur': 3792,\n",
       " 'gas': 2321,\n",
       " 'coal': 1300,\n",
       " 'hydroelectr': 2725,\n",
       " 'plant': 4975,\n",
       " 'wind power': 8505,\n",
       " 'power reach': 5829,\n",
       " 'it now': 3204,\n",
       " 'now employ': 3890,\n",
       " 'natur gas': 3793,\n",
       " 'power plant': 5805,\n",
       " 'wind power reach': 8516,\n",
       " 'power reach 100k': 5830,\n",
       " 'wind power reach 100k': 8517,\n",
       " 'power reach 100k job': 5831,\n",
       " 'your': 8982,\n",
       " 'futur': 2303,\n",
       " 'buy': 1063,\n",
       " 'internet': 3003,\n",
       " 'data': 1523,\n",
       " 'product': 6368,\n",
       " 'data to': 1527,\n",
       " 'your product': 8987,\n",
       " 'shark': 6794,\n",
       " 'blood': 975,\n",
       " 'contain': 1402,\n",
       " 'antibodi': 599,\n",
       " 'much': 3753,\n",
       " 'smaller': 6870,\n",
       " 'those': 7751,\n",
       " 'found': 2245,\n",
       " 'human': 2694,\n",
       " 'these': 7700,\n",
       " 'could': 1439,\n",
       " 'potenti': 5583,\n",
       " 'be': 824,\n",
       " 'use': 8170,\n",
       " 'as': 688,\n",
       " 'treatment': 8059,\n",
       " 'brain': 1006,\n",
       " 'diseas': 1656,\n",
       " 'which': 8441,\n",
       " 'are': 625,\n",
       " 'hard': 2483,\n",
       " 'treat': 8057,\n",
       " 'becaus': 874,\n",
       " 'larger': 3338,\n",
       " 'molecul': 3694,\n",
       " 'cross': 1495,\n",
       " 'found in': 2249,\n",
       " 'in human': 2866,\n",
       " 'could potenti': 1459,\n",
       " 'potenti be': 5584,\n",
       " 'be use': 866,\n",
       " 'use as': 8172,\n",
       " 'treatment for': 8060,\n",
       " 'for brain': 2195,\n",
       " 'which are': 8442,\n",
       " 'to treat': 7998,\n",
       " 'can not': 1121,\n",
       " 'the brain': 7362,\n",
       " 'potenti be use': 5585,\n",
       " 'be use as': 867,\n",
       " 'potenti be use as': 5586,\n",
       " 'instal': 2980,\n",
       " 'video': 8205,\n",
       " 'camera': 1101,\n",
       " 'into': 3011,\n",
       " 'his': 2590,\n",
       " 'right': 6605,\n",
       " 'eye': 2038,\n",
       " 'gun': 2453,\n",
       " 'accid': 319,\n",
       " 'left': 3371,\n",
       " 'blind': 970,\n",
       " 'one': 4113,\n",
       " 'kid': 3279,\n",
       " 'he': 2547,\n",
       " 'put': 6426,\n",
       " 'there': 7671,\n",
       " 'instal a': 2981,\n",
       " 'a video': 287,\n",
       " 'in one': 2884,\n",
       " 'as a': 689,\n",
       " 'put a': 6427,\n",
       " 'commit': 1348,\n",
       " '100': 11,\n",
       " 'percent': 4451,\n",
       " 'renew': 6534,\n",
       " 'by': 1066,\n",
       " '2021': 59,\n",
       " 'commit to': 1351,\n",
       " 'to 100': 7807,\n",
       " '100 percent': 15,\n",
       " 'percent renew': 4454,\n",
       " 'renew electr': 6536,\n",
       " 'electr by': 1864,\n",
       " 'by the': 1083,\n",
       " 'the year': 7650,\n",
       " 'to 100 percent': 7808,\n",
       " '100 percent renew': 17,\n",
       " 'by the year': 1086,\n",
       " 'to 100 percent renew': 7809,\n",
       " 'obtain': 3918,\n",
       " 'ethanol': 1973,\n",
       " 'consid': 1392,\n",
       " 'an': 458,\n",
       " 'how can': 2640,\n",
       " 'can i': 1118,\n",
       " 'how can i': 2642,\n",
       " 'spot': 7017,\n",
       " 'where': 8394,\n",
       " 'big': 934,\n",
       " 'happen': 2472,\n",
       " 'know': 3298,\n",
       " 'center': 1193,\n",
       " 'univers': 8130,\n",
       " 'go': 2375,\n",
       " 'net': 3816,\n",
       " 'forc': 2233,\n",
       " 'zero': 8995,\n",
       " 'act': 337,\n",
       " 'all': 404,\n",
       " 'direct': 1643,\n",
       " 'is there': 3120,\n",
       " 'there a': 7672,\n",
       " 'spot where': 7018,\n",
       " 'where the': 8400,\n",
       " 'do we': 1704,\n",
       " 'we know': 8296,\n",
       " 'it is': 3192,\n",
       " 'it the': 3228,\n",
       " 'the center': 7369,\n",
       " 'center of': 1194,\n",
       " 'the univers': 7623,\n",
       " 'you go': 8969,\n",
       " 'there is': 7690,\n",
       " 'a net': 216,\n",
       " 'forc of': 2234,\n",
       " 'in all': 2832,\n",
       " 'all direct': 405,\n",
       " 'is there a': 3121,\n",
       " 'do we know': 1707,\n",
       " 'is it the': 3086,\n",
       " 'the center of': 7370,\n",
       " 'center of the': 1195,\n",
       " 'of the univers': 4026,\n",
       " 'in all direct': 2833,\n",
       " 'the center of the': 7371,\n",
       " 'center of the univers': 1196,\n",
       " 'plan': 4776,\n",
       " 'has': 2491,\n",
       " 'succeed': 7112,\n",
       " 'younger': 8981,\n",
       " 'want': 8231,\n",
       " 'car': 1151,\n",
       " 'plan has': 4791,\n",
       " 'electr car': 1865,\n",
       " 'plan has succeed': 4792,\n",
       " 'plan has succeed the': 4793,\n",
       " 'today': 8015,\n",
       " 'some': 6936,\n",
       " 'super': 7141,\n",
       " 'glue': 2372,\n",
       " 'color': 1331,\n",
       " 'print': 6145,\n",
       " 'my': 3778,\n",
       " 'tshirt': 8085,\n",
       " 'surpris': 7161,\n",
       " 'got': 2405,\n",
       " 'realli': 6479,\n",
       " 'hot': 2621,\n",
       " 'had': 2455,\n",
       " 'land': 3326,\n",
       " 'start': 7040,\n",
       " 'smoke': 6878,\n",
       " 'quit': 6436,\n",
       " 'lot': 3495,\n",
       " 'anyon': 603,\n",
       " 'idea': 2749,\n",
       " 'on the': 4095,\n",
       " 'the color': 7378,\n",
       " 'print of': 6157,\n",
       " 'of my': 3990,\n",
       " 'my tshirt': 3782,\n",
       " 'to my': 7923,\n",
       " 'and start': 554,\n",
       " 'start to': 7043,\n",
       " 'a lot': 197,\n",
       " 'doe anyon': 1717,\n",
       " 'have an': 2514,\n",
       " 'idea of': 2750,\n",
       " 'of whi': 4046,\n",
       " 'this happen': 7742,\n",
       " 'print of my': 6158,\n",
       " 'print of my tshirt': 6159,\n",
       " 'basic': 813,\n",
       " 'incom': 2944,\n",
       " 'necessari': 3803,\n",
       " 'univers basic': 8131,\n",
       " 'basic incom': 814,\n",
       " 'is go': 3066,\n",
       " 'go to': 2381,\n",
       " 'to be': 7823,\n",
       " 'be necessari': 854,\n",
       " 'univers basic incom': 8132,\n",
       " 'is go to': 3067,\n",
       " 'go to be': 2382,\n",
       " 'is go to be': 3068,\n",
       " 'two': 8099,\n",
       " 'infant': 2960,\n",
       " 'immun': 2809,\n",
       " 'cell': 1184,\n",
       " 'their': 7652,\n",
       " 'cancer': 1134,\n",
       " 'medic': 3608,\n",
       " 'children': 1241,\n",
       " 'genet': 2338,\n",
       " 'engin': 1937,\n",
       " 'anoth': 593,\n",
       " 'person': 4469,\n",
       " 'treat with': 8058,\n",
       " 'immun cell': 2810,\n",
       " 'in a': 2822,\n",
       " 'with genet': 8806,\n",
       " 'genet engin': 2339,\n",
       " 'from anoth': 2269,\n",
       " 'anoth person': 594,\n",
       " 'with genet engin': 8807,\n",
       " 'from anoth person': 2270,\n",
       " 'with genet engin tcell': 8808,\n",
       " 'planet': 4878,\n",
       " 'sustain': 7168,\n",
       " 'tecton': 7234,\n",
       " 'plate': 5127,\n",
       " 'activ': 341,\n",
       " 'was': 8241,\n",
       " 'entir': 1947,\n",
       " 'cover': 1475,\n",
       " 'singl': 6848,\n",
       " 'massiv': 3567,\n",
       " 'for a': 2191,\n",
       " 'planet to': 4943,\n",
       " 'to have': 7889,\n",
       " 'tecton plate': 7235,\n",
       " 'plate activ': 5128,\n",
       " 'would a': 8909,\n",
       " 'a planet': 234,\n",
       " 'planet that': 4938,\n",
       " 'that was': 7331,\n",
       " 'by a': 1078,\n",
       " 'a singl': 258,\n",
       " 'planet to have': 4944,\n",
       " 'tecton plate activ': 7236,\n",
       " 'plate activ would': 5129,\n",
       " 'a planet that': 235,\n",
       " 'planet that was': 4941,\n",
       " 'by a singl': 1079,\n",
       " 'planet to have sustain': 4945,\n",
       " 'plate activ would a': 5130,\n",
       " 'planet that was entir': 4942,\n",
       " 'bodi': 980,\n",
       " 'reject': 6521,\n",
       " 'transplant': 8051,\n",
       " 'organ': 4172,\n",
       " 'tissu': 7802,\n",
       " 'proceed': 6276,\n",
       " 'destroy': 1604,\n",
       " 'them': 7658,\n",
       " 'but': 1045,\n",
       " 'kill': 3280,\n",
       " 'parasit': 4395,\n",
       " 'doe the': 1731,\n",
       " 'the human': 7455,\n",
       " 'human bodi': 2697,\n",
       " 'tissu and': 7803,\n",
       " 'proceed to': 6280,\n",
       " 'to destroy': 7853,\n",
       " 'them but': 7659,\n",
       " 'but it': 1054,\n",
       " 'it doesnt': 3171,\n",
       " 'whi doe the': 8424,\n",
       " 'doe the human': 1733,\n",
       " 'the human bodi': 7456,\n",
       " 'proceed to destroy': 6281,\n",
       " 'but it doesnt': 1055,\n",
       " 'proceed to destroy them': 6282,\n",
       " 'hundr': 2717,\n",
       " 'most': 3732,\n",
       " 'promin': 6378,\n",
       " 'scientist': 6705,\n",
       " 'sign': 6824,\n",
       " 'open': 4127,\n",
       " 'letter': 3395,\n",
       " 'monday': 3695,\n",
       " 'call': 1096,\n",
       " 'urgent': 8159,\n",
       " 'polit': 5302,\n",
       " 'action': 340,\n",
       " 'address': 350,\n",
       " 'global': 2367,\n",
       " 'catastroph': 1175,\n",
       " 'face': 2039,\n",
       " 'mankind': 3543,\n",
       " 'other': 4175,\n",
       " 'speci': 6990,\n",
       " 'hundr of': 2718,\n",
       " 'world most': 8902,\n",
       " 'and scientist': 549,\n",
       " 'sign an': 6826,\n",
       " 'an open': 477,\n",
       " 'on monday': 4089,\n",
       " 'call for': 1097,\n",
       " 'polit action': 5303,\n",
       " 'to address': 7815,\n",
       " 'address the': 351,\n",
       " 'the global': 7433,\n",
       " 'and other': 543,\n",
       " 'other speci': 4178,\n",
       " 'of the world': 4029,\n",
       " 'the world most': 7648,\n",
       " 'polit action to': 5304,\n",
       " 'to address the': 7816,\n",
       " 'of the world most': 4030,\n",
       " 'polit action to address': 5305,\n",
       " 'social': 6906,\n",
       " 'behavior': 908,\n",
       " 'tardigrad': 7209,\n",
       " 'interact': 2995,\n",
       " 'what is': 8354,\n",
       " 'is the': 3111,\n",
       " 'and if': 514,\n",
       " 'if so': 2779,\n",
       " 'so how': 6888,\n",
       " 'interact with': 2996,\n",
       " 'one anoth': 4114,\n",
       " 'what is the': 8357,\n",
       " 'and if so': 515,\n",
       " 'if so how': 2780,\n",
       " 'china': 1242,\n",
       " 'build': 1033,\n",
       " '50': 102,\n",
       " 'amp': 457,\n",
       " 'solar': 6912,\n",
       " 'grid': 2438,\n",
       " '2050': 66,\n",
       " 'want to': 8233,\n",
       " 'to build': 7834,\n",
       " 'build a': 1034,\n",
       " 'solar power': 6922,\n",
       " 'power grid': 5747,\n",
       " 'by 2050': 1074,\n",
       " 'to build a': 7835,\n",
       " 'power grid by': 5748,\n",
       " 'power grid by 2050': 5749,\n",
       " 'current': 1505,\n",
       " 'limit': 3431,\n",
       " 'desalin': 1596,\n",
       " 'what are': 8341,\n",
       " 'are the': 655,\n",
       " 'the current': 7386,\n",
       " 'limit of': 3432,\n",
       " 'plant global': 5007,\n",
       " 'what are the': 8342,\n",
       " 'way': 8268,\n",
       " 'possibl': 5482,\n",
       " 'revers': 6590,\n",
       " 'black': 962,\n",
       " 'hole': 2601,\n",
       " 'it in': 3189,\n",
       " 'in ani': 2836,\n",
       " 'ani way': 584,\n",
       " 'possibl to': 5529,\n",
       " 'to revers': 7957,\n",
       " 'a black': 141,\n",
       " 'black hole': 964,\n",
       " 'in ani way': 2837,\n",
       " 'possibl to revers': 5553,\n",
       " 'a black hole': 142,\n",
       " 'possibl to revers a': 5554,\n",
       " 'success': 7113,\n",
       " 'develop': 1610,\n",
       " 'rice': 6597,\n",
       " 'three': 7758,\n",
       " 'differ': 1630,\n",
       " 'protein': 6392,\n",
       " 'stop': 7072,\n",
       " 'hiv': 2598,\n",
       " 'enter': 1946,\n",
       " 'find': 2119,\n",
       " 'lead': 3358,\n",
       " 'less': 3389,\n",
       " 'cost': 1428,\n",
       " 'easier': 1830,\n",
       " 'produc': 6315,\n",
       " 'spread': 7020,\n",
       " 'particular': 4410,\n",
       " 'develop a': 1611,\n",
       " 'plant that': 5049,\n",
       " 'protein that': 6393,\n",
       " 'that can': 7297,\n",
       " 'can stop': 1126,\n",
       " 'human cell': 2699,\n",
       " 'the find': 7421,\n",
       " 'could lead': 1453,\n",
       " 'lead to': 3359,\n",
       " 'to a': 7812,\n",
       " 'way of': 8269,\n",
       " 'of produc': 4000,\n",
       " 'that could': 7302,\n",
       " 'stop the': 7074,\n",
       " 'spread of': 7021,\n",
       " 'the develop': 7390,\n",
       " 'plant that express': 5050,\n",
       " 'could lead to': 1454,\n",
       " 'lead to a': 3360,\n",
       " 'plant that express three': 5051,\n",
       " 'could lead to a': 1455,\n",
       " 'artifici': 683,\n",
       " 'sun': 7131,\n",
       " 'achiev': 331,\n",
       " 'fusion': 2300,\n",
       " 'breakthrough': 1016,\n",
       " 'vote': 8221,\n",
       " '2020': 56,\n",
       " 'you to': 8976,\n",
       " 'to vote': 8006,\n",
       " 'announc': 589,\n",
       " 'billion': 944,\n",
       " 'invest': 3025,\n",
       " 'batteri': 816,\n",
       " 'invest in': 3026,\n",
       " 'and batteri': 492,\n",
       " 'point': 5210,\n",
       " 'liquid': 3438,\n",
       " 'becom': 878,\n",
       " 'solid': 6931,\n",
       " 'at what': 752,\n",
       " 'what point': 8365,\n",
       " 'point doe': 5217,\n",
       " 'doe a': 1712,\n",
       " 'a liquid': 193,\n",
       " 'that it': 7314,\n",
       " 'consid a': 1393,\n",
       " 'a solid': 263,\n",
       " 'at what point': 753,\n",
       " 'point doe a': 5218,\n",
       " 'point doe a liquid': 5219,\n",
       " 'should': 6805,\n",
       " 'wipe': 8584,\n",
       " 'mosquito': 3731,\n",
       " 'off': 4050,\n",
       " 'earth': 1815,\n",
       " 'should we': 6808,\n",
       " 'wipe mosquito': 8585,\n",
       " 'off the': 4051,\n",
       " 'the earth': 7398,\n",
       " 'wipe mosquito off': 8586,\n",
       " 'of the earth': 4015,\n",
       " 'wipe mosquito off the': 8587,\n",
       " 'america': 451,\n",
       " 'roadway': 6618,\n",
       " 'total': 8031,\n",
       " 'disast': 1648,\n",
       " 'rough': 6641,\n",
       " '25': 71,\n",
       " 'out': 4199,\n",
       " '30': 79,\n",
       " 'panel': 4383,\n",
       " 'broke': 1027,\n",
       " 'within': 8853,\n",
       " 'week': 8318,\n",
       " 'after': 368,\n",
       " 'pump': 6416,\n",
       " 'million': 3653,\n",
       " 'over': 4312,\n",
       " '65': 118,\n",
       " 'first solar': 2133,\n",
       " 'is a': 3040,\n",
       " 'out of': 4234,\n",
       " 'of 30': 3934,\n",
       " 'on it': 4085,\n",
       " 'it broke': 3159,\n",
       " 'within a': 8859,\n",
       " 'million into': 3657,\n",
       " 'over 65': 4342,\n",
       " 'year of': 8950,\n",
       " 'within a week': 8861,\n",
       " 'over 65 year': 4343,\n",
       " 'within a week after': 8862,\n",
       " 'over 65 year of': 4344,\n",
       " 'peopl': 4436,\n",
       " 'better': 922,\n",
       " 'memori': 3616,\n",
       " 'make some': 3528,\n",
       " 'some peopl': 6939,\n",
       " 'peopl have': 4439,\n",
       " 'have a': 2513,\n",
       " 'a better': 138,\n",
       " 'than other': 7285,\n",
       " 'what make some': 8363,\n",
       " 'some peopl have': 6940,\n",
       " 'far': 2061,\n",
       " 'see': 6738,\n",
       " 'dinosaur': 1641,\n",
       " 'aliv': 403,\n",
       " 'if we': 2793,\n",
       " 'from earth': 2273,\n",
       " 'earth could': 1820,\n",
       " 'could we': 1467,\n",
       " 'we see': 8302,\n",
       " 'see the': 6741,\n",
       " 'tesla': 7250,\n",
       " 'roof': 6632,\n",
       " 'tile': 7775,\n",
       " 'home': 2605,\n",
       " 'such': 7117,\n",
       " 'deal': 1539,\n",
       " 'new solar': 3840,\n",
       " 'solar roof': 6925,\n",
       " 'roof tile': 6633,\n",
       " 'home batteri': 2607,\n",
       " 'such a': 7118,\n",
       " 'solar roof tile': 6926,\n",
       " 'sent': 6768,\n",
       " 'messag': 3626,\n",
       " 'tri': 8065,\n",
       " 'talk': 7206,\n",
       " 'alien': 402,\n",
       " 'astronom': 736,\n",
       " 'radio': 6441,\n",
       " 'star': 7034,\n",
       " 'system': 7181,\n",
       " 'known': 3305,\n",
       " 'habit': 2454,\n",
       " 'nearbi': 3799,\n",
       " 'receiv': 6484,\n",
       " 'repli': 6549,\n",
       " 'we just': 8295,\n",
       " 'sent a': 6769,\n",
       " 'a messag': 204,\n",
       " 'messag to': 3627,\n",
       " 'to tri': 7999,\n",
       " 'tri to': 8066,\n",
       " 'to talk': 7980,\n",
       " 'one of': 4119,\n",
       " 'known to': 3307,\n",
       " 'contain a': 1403,\n",
       " 'potenti habit': 5604,\n",
       " 'planet and': 4882,\n",
       " 'and it': 520,\n",
       " 'enough that': 1943,\n",
       " 'that we': 7332,\n",
       " 'we could': 8282,\n",
       " 'receiv a': 6485,\n",
       " 'in less': 2871,\n",
       " 'less than': 3390,\n",
       " 'than 25': 7277,\n",
       " 'a messag to': 205,\n",
       " 'to tri to': 8000,\n",
       " 'one of the': 4120,\n",
       " 'potenti habit planet': 5605,\n",
       " 'planet and it': 4886,\n",
       " 'enough that we': 1944,\n",
       " 'in less than': 2872,\n",
       " 'potenti habit planet and': 5606,\n",
       " 'planet and it nearbi': 4887,\n",
       " 'fundament': 2298,\n",
       " 'isnt': 3141,\n",
       " 'sad': 6654,\n",
       " 'can you': 1129,\n",
       " 'do better': 1683,\n",
       " 'here': 2576,\n",
       " 'rocket': 6627,\n",
       " 'theoret': 7667,\n",
       " 'machin': 3504,\n",
       " 'magnet': 3515,\n",
       " 'launch': 3350,\n",
       " 'orbit': 4166,\n",
       " 'without': 8865,\n",
       " 'chemic': 1232,\n",
       " 'propel': 6382,\n",
       " 'to make': 7916,\n",
       " 'to launch': 7911,\n",
       " 'launch a': 3351,\n",
       " 'of earth': 3961,\n",
       " 'earth orbit': 1824,\n",
       " 'without chemic': 8873,\n",
       " 'to make a': 7917,\n",
       " 'who': 8457,\n",
       " 'studi': 7099,\n",
       " 'fossil': 2243,\n",
       " 'incred': 2948,\n",
       " 'site': 6851,\n",
       " 'texa': 7270,\n",
       " 'ask': 717,\n",
       " 'us': 8160,\n",
       " 'anyth': 604,\n",
       " 'we are': 8278,\n",
       " 'from an': 2268,\n",
       " 'an incred': 473,\n",
       " 'in texa': 2907,\n",
       " 'call the': 1098,\n",
       " 'ask us': 719,\n",
       " 'us anyth': 8162,\n",
       " 'ask us anyth': 720,\n",
       " 'cloth': 1296,\n",
       " 'feel': 2094,\n",
       " 'dri': 1772,\n",
       " 'soft': 6909,\n",
       " 'whi do': 8413,\n",
       " 'when you': 8393,\n",
       " 'out of the': 4236,\n",
       " 'ceo': 1200,\n",
       " 'challeng': 1209,\n",
       " '0': 0,\n",
       " 'ceo elon': 1201,\n",
       " 'to go': 7883,\n",
       " 'with 0': 8607,\n",
       " 'after be': 371,\n",
       " 'be call': 838,\n",
       " 'ceo elon musk': 1202,\n",
       " 'with 0 subsidi': 8608,\n",
       " 'with 0 subsidi after': 8609,\n",
       " 'uranus': 8155,\n",
       " 'axi': 786,\n",
       " 'rotat': 6640,\n",
       " 'onto': 4126,\n",
       " 'side': 6821,\n",
       " 'mean': 3592,\n",
       " 'spin': 7009,\n",
       " 'down': 1760,\n",
       " 'instead': 2984,\n",
       " 'signific': 6833,\n",
       " 'effect': 1843,\n",
       " 'earthlik': 1827,\n",
       " 'sort': 6953,\n",
       " 'life': 3402,\n",
       " 'condit': 1384,\n",
       " 'ideal': 2751,\n",
       " 'mean it': 3593,\n",
       " 'up and': 8145,\n",
       " 'and down': 500,\n",
       " 'instead of': 2985,\n",
       " 'doe this': 1735,\n",
       " 'effect on': 1847,\n",
       " 'the planet': 7535,\n",
       " 'planet climat': 4891,\n",
       " 'climat could': 1288,\n",
       " 'could an': 1442,\n",
       " 'an earthlik': 467,\n",
       " 'planet with': 4955,\n",
       " 'with that': 8833,\n",
       " 'sort of': 6954,\n",
       " 'sustain life': 7169,\n",
       " 'if all': 2762,\n",
       " 'all other': 409,\n",
       " 'up and down': 8146,\n",
       " 'effect on the': 1848,\n",
       " 'on the planet': 4102,\n",
       " 'planet climat could': 4892,\n",
       " 'planet with that': 4960,\n",
       " 'effect on the planet': 1849,\n",
       " 'planet climat could an': 4893,\n",
       " 'planet with that sort': 4961,\n",
       " 'show': 6810,\n",
       " 'student': 7098,\n",
       " 'learn': 3365,\n",
       " 'textbook': 7274,\n",
       " 'screen': 6719,\n",
       " 'while': 8451,\n",
       " 'form': 2237,\n",
       " 'technolog': 7228,\n",
       " 'digit': 1638,\n",
       " 'access': 317,\n",
       " 'portabl': 5432,\n",
       " 'wrong': 8938,\n",
       " 'automat': 773,\n",
       " 'serv': 6779,\n",
       " 'read': 6472,\n",
       " 'a new': 217,\n",
       " 'new studi': 3841,\n",
       " 'show that': 6812,\n",
       " 'that student': 7323,\n",
       " 'more effect': 3713,\n",
       " 'print textbook': 6160,\n",
       " 'new form': 3833,\n",
       " 'form of': 2238,\n",
       " 'are more': 642,\n",
       " 'portabl it': 5436,\n",
       " 'it would': 3239,\n",
       " 'would be': 8910,\n",
       " 'assum that': 733,\n",
       " 'a new studi': 220,\n",
       " 'print textbook than': 6161,\n",
       " 'new form of': 3834,\n",
       " 'portabl it would': 5437,\n",
       " 'print textbook than screen': 6162,\n",
       " 'portabl it would be': 5438,\n",
       " 'between': 927,\n",
       " 'what the': 8366,\n",
       " 'the differ': 7391,\n",
       " 'differ between': 1631,\n",
       " 'what the differ': 8367,\n",
       " 'the differ between': 7392,\n",
       " 'what the differ between': 8368,\n",
       " 'onli': 4124,\n",
       " 'live': 3453,\n",
       " 'day': 1532,\n",
       " 'evolv': 2001,\n",
       " 'fast': 2072,\n",
       " 'which onli': 8447,\n",
       " 'a day': 158,\n",
       " 'than a': 7280,\n",
       " 'a human': 183,\n",
       " 'than a human': 7281,\n",
       " 'lose': 3489,\n",
       " 'status': 7052,\n",
       " 'it possibl': 3208,\n",
       " 'possibl for': 5492,\n",
       " 'to lose': 7915,\n",
       " 'is it possibl': 3081,\n",
       " 'it possibl for': 3209,\n",
       " 'possibl for black': 5499,\n",
       " 'is it possibl for': 3082,\n",
       " 'possibl for black hole': 5500,\n",
       " 'wireless': 8595,\n",
       " 'charger': 1223,\n",
       " 'wireless charger': 8596,\n",
       " 'wireless charger work': 8597,\n",
       " 'element': 1876,\n",
       " 'radioact': 6443,\n",
       " 'higher': 2585,\n",
       " 'whi are': 8404,\n",
       " 'when all': 8377,\n",
       " 'much higher': 3756,\n",
       " 'poorest': 5378,\n",
       " 'countri': 1471,\n",
       " 'aim': 391,\n",
       " 'green': 2429,\n",
       " 'energi': 1919,\n",
       " 'repres': 6553,\n",
       " 'nation': 3790,\n",
       " 'pledg': 5166,\n",
       " 'need': 3804,\n",
       " 'poorest countri': 5379,\n",
       " 'countri to': 1472,\n",
       " 'for 100': 2188,\n",
       " 'green energi': 2430,\n",
       " 'pledg to': 5173,\n",
       " 'to generat': 7880,\n",
       " 'generat all': 2334,\n",
       " 'all their': 413,\n",
       " 'their futur': 7655,\n",
       " 'energi need': 1927,\n",
       " 'from renew': 2275,\n",
       " 'poorest countri to': 5380,\n",
       " 'pledg to generat': 5180,\n",
       " 'poorest countri to aim': 5381,\n",
       " 'pledg to generat all': 5181,\n",
       " 'fuel': 2289,\n",
       " 'plastic': 5091,\n",
       " 'bottl': 999,\n",
       " 'deriv': 1594,\n",
       " 'demonstr': 1579,\n",
       " 'base': 811,\n",
       " 'bioengin': 951,\n",
       " 'bacteria': 796,\n",
       " 'econom': 1838,\n",
       " 'feasibl': 2088,\n",
       " 'sourc': 6961,\n",
       " 'plastic soda': 5112,\n",
       " 'are all': 627,\n",
       " 'deriv from': 1595,\n",
       " 'scientist have': 6711,\n",
       " ...}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfsvc_grid.best_estimator_.named_steps.tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation:\n",
      "\n",
      "Accuracy: 0.95 (+/- 0.02) [Naive Bayes]\n",
      "Accuracy: 0.95 (+/- 0.02) [LogReg]\n",
      "Accuracy: 0.96 (+/- 0.01) [SVC]\n",
      "Accuracy: 0.96 (+/- 0.02) [StackingClassifier]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "import numpy as np\n",
    "\n",
    "X=TfidfVectorizer(ngram_range=(1,4), tokenizer=SnowballTokenizer(), max_features=9500).fit_transform(X_train['processed'])\n",
    "\n",
    "y= y_train\n",
    "\n",
    "clf1 = MultinomialNB()\n",
    "clf2 = LogisticRegression()\n",
    "clf3 = SVC(kernel='linear', C= .8)\n",
    "lr = LogisticRegression()\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3], \n",
    "                          meta_classifier=lr)\n",
    "\n",
    "print('10-fold cross validation:\\n')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, sclf], \n",
    "                      ['Naive Bayes', \n",
    "                       'LogReg', \n",
    "                       'SVC',\n",
    "                       'StackingClassifier']):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, X, y, \n",
    "                                              cv=10, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))\n",
    "# It makes almost not difference between tfidf and countvec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**^The above Stacking Classifier is promising, but after lots of parameter tuning I've settled on this pipeline:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipe= Pipeline(steps=[\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,4), tokenizer=SnowballTokenizer(), max_features=9500)),\n",
    "    ('svc', SVC(C= .8, kernel='linear' ))\n",
    "])\n",
    "# With 5-fold Cross Validation, this gets 98% accuracy on test set (processed) data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./tf_svc_pipe.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(final_pipe, './tf_svc_pipe.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=9500, min_df=1,\n",
       "        ngram_range=(1, 4), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pipe.fit(X_train['processed'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9959919839679359"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pipe.score(X_train['processed'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9799599198396793"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pipe.score(X_test['processed'], y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
